---
layout: post
title: "How Do Deepfakes Move? Motion Magnification for Deepfake Source Detection"
date: 2024-02-20
categories: ComputerVision Paper
---

## Important Terms in this paper

# Source generator detection
 refers to the process of identifying whether digital content, such as images or videos, has been artificially generated by a computer algorithm. 
 This is particularly relevant in the era of advanced generative models, like Generative Adversarial Networks (GANs), 
 which can produce highly realistic images, videos, or other types of media that are indistinguishable from real, authentic content to the unaided eye. 

# Traditional phase-based magnification 
Phase-Based Motion Magnification is a technique used in video processing and computer vision to **amplify subtle movements** in videos that are invisible to the naked eye. 
This method is particularly useful in scenarios where observing minute motions is crucial, such as in structural engineering to detect small deformations in buildings or bridges, in medicine to amplify the movements of a patient's skin or muscles, or in surveillance to enhance tiny movements in a scene.

The traditional approach to phase-based motion magnification involves:
Decomposing the video signal into different spatial frequencies and orientations using complex steerable pyramids or wavelet transforms.
Isolating the phase component of the signal in these frequencies and orientations.
Amplifying the phase variations over time, which correspond to motion, by a factor without altering the amplitude component.
Reconstructing the video from the modified frequency components, resulting in a video where the subtle motions are magnified.
This method is preferred for its ability to preserve the original video's appearance while amplifying motion, avoiding the introduction of artificial artifacts.

# Generative Adversarial Networks (GANs)

A GAN consists of two neural networks: a **generator (G)** and a **discriminator (D)**, which are trained simultaneously through an adversarial process.

*   **Generator (G):** Tries to generate data that resembles the real data. It takes a random noise vector zzz as input and produces a data instance G(z)G(z)G(z) that aims to mimic the real data distribution.
*   **Discriminator (D):** Tries to distinguish between real data instances and fake data instances produced by the generator. It outputs a probability D(x)D(x)D(x) that xxx is a real data instance rather than a fake one.

**Adversarial Training Process:** The training involves a min-max game where the generator tries to minimize the following objective function while the discriminator tries to maximize it:

$min⁡Gmax⁡DV(D,G)\=Ex∼pdata(x)\[log⁡D(x)\]+Ez∼pz(z)\[log⁡(1−D(G(z)))\]\\min\_{G} \\max\_{D} V(D, G) = \\mathbb{E}\_{x \\sim p\_{\\text{data}}(x)}\[\\log D(x)\] + \\mathbb{E}\_{z \\sim p\_{z}(z)}\[\\log (1 - D(G(z)))\]minG​maxD​V(D,G)\=Ex∼pdata​(x)​\[logD(x)\]+Ez∼pz​(z)​\[log(1−D(G(z)))\]$

Here, pdata(x)p\_{\\text{data}}(x)pdata​(x) is the real data distribution, and pz(z)p\_{z}(z)pz​(z) is the distribution of the generator's input noise.

